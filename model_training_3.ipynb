{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Training 3\n",
    "In this notebook we are exploring Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q spacy\n",
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 22:40:15.388711: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-02 22:40:15.389136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-02 22:40:15.389293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'helpers' from '/notebooks/helpers.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import gensim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# import custom helper module\n",
    "import importlib\n",
    "import helpers\n",
    "importlib.reload(helpers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pickle file found. Loading and cleaning dataset.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[9522] tan triste parejas hace aÃ±os decidan separarse --> 1\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = helpers.load_dataset(\"TRAINING_DATA.txt\")\n",
    "\n",
    "# print message\n",
    "helpers.print_text(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_tok = [nltk.word_tokenize(text) for text in X_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# import gensim.downloader as api\n",
    "# import sys\n",
    "# sys.path.append('I:\\\\ai_models\\\\spanish_word2vec')\n",
    "\n",
    "# import os\n",
    "\n",
    "# model_path = r\"I:\\ai_models\\spanish_word2vec\\complete.model\"\n",
    "# print(os.path.exists(model_path))  # Should return True if the file exists\n",
    "\n",
    "# # train Word2Vec on tokenized dataset\n",
    "# # w2v_model = Word2Vec(sentences=X_train_tok, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# # save model\n",
    "# # w2v_model.save(\"word2vec.model\")\n",
    "# model_path = r'file:///I:/ai_models/spanish_word2vec/complete.model'\n",
    "# w2v_model = Word2Vec.load(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading spaCy and Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta [ 5.6426e+00 -2.2479e-01  2.4950e+00  1.2205e+00  5.6342e+00 -4.4999e+00\n",
      " -4.5745e-01  8.7406e-01  3.1076e+00 -1.3380e+00  1.0341e+00  7.2001e+00\n",
      "  4.6250e-01 -4.8635e+00  3.7515e+00  6.7590e-03 -8.3981e-02 -4.4031e+00\n",
      "  6.2830e+00  1.3133e+00  1.6437e+00 -2.3727e-02 -3.3668e-01  2.7206e+00\n",
      "  2.4771e+00  4.4419e+00  1.1142e+00  2.7833e+00 -4.4402e+00  6.9588e-01\n",
      "  9.1691e-01  3.9655e+00 -2.9583e-01 -4.8001e+00 -3.2515e+00  1.6547e+00\n",
      "  2.6210e+00  5.4598e-01  3.2995e+00  1.4479e+00  1.3022e+00  9.5587e-01\n",
      " -1.8186e+00 -3.0594e+00  1.0719e+00  4.2435e+00  3.4267e+00  7.8943e+00\n",
      " -2.8035e+00 -1.0325e+00  1.0798e+00  4.3054e+00  3.8553e+00 -4.1107e-01\n",
      " -3.3289e+00  3.0916e+00 -1.2414e+00 -4.1578e+00 -5.4438e+00  7.7858e-01\n",
      "  4.7921e+00  7.7843e-01  4.6567e-01 -3.6170e-01  4.1328e+00  3.7598e-01\n",
      "  1.2302e-01 -1.4008e+00 -2.8097e+00  1.2602e+00 -4.9633e+00  4.6132e-03\n",
      "  2.6106e+00 -1.6016e+00 -4.5058e+00 -9.8519e-01 -3.0157e+00 -5.8176e+00\n",
      "  2.0709e-01  2.0357e-01  3.7225e+00 -1.4230e+00 -4.5818e+00  3.2194e+00\n",
      "  6.6151e-01  3.3869e-02 -6.7312e+00 -2.0575e+00 -5.1677e-01  2.6401e-01\n",
      " -6.4749e+00 -1.6142e+00 -7.6119e+00 -1.5227e+00  3.7523e+00  4.5308e+00\n",
      "  1.6167e+00  2.0971e+00  6.5984e-02 -1.9917e+00 -2.6153e+00 -1.9639e+00\n",
      " -1.1553e+00  5.9021e-01  2.6442e+00 -7.0035e+00  1.7143e+00 -4.1938e+00\n",
      "  6.1029e+00 -1.6368e-01  1.6825e+00 -3.3967e+00  1.9555e+00  3.9237e+00\n",
      "  3.1674e+00 -2.9696e+00 -1.8982e+00  8.5489e+00  9.5858e-01  8.2272e+00\n",
      "  2.0552e+00 -1.6705e+00 -2.6492e+00 -3.4674e+00  2.7449e-01  1.1330e+00\n",
      "  1.0005e-01 -3.1821e+00  2.4145e+00 -3.4235e+00  3.8864e+00 -1.3033e+00\n",
      "  9.8282e-01 -1.9394e+00  2.7179e+00 -2.2600e+00 -5.1893e+00  4.9253e+00\n",
      "  1.7372e+00  1.5051e+00 -1.6959e+00  6.1433e+00  3.0704e+00  2.4589e-01\n",
      " -6.7401e+00  3.1428e-01  4.3292e-01 -1.8868e+00 -3.6567e+00  2.1474e+00\n",
      " -4.1623e-01  7.0155e-01  8.0852e-01 -6.4534e-01  9.3637e-01  4.1494e+00\n",
      "  1.2902e+00 -3.6866e+00 -7.3414e+00  9.8366e-01  5.7057e+00  3.6875e+00\n",
      " -4.3901e+00 -3.2331e-01  5.0926e+00  4.1212e+00 -2.4234e+00 -1.2351e-01\n",
      " -9.6911e-01 -3.3998e+00  3.1934e+00  3.0006e+00 -2.6887e+00  2.0615e+00\n",
      " -9.6299e-01  2.3538e-01 -7.2761e+00 -4.7088e+00 -5.4413e+00 -1.2316e+00\n",
      "  2.1682e+00 -1.8510e+00  1.8308e+00  7.1043e-01 -2.0744e+00 -3.2184e+00\n",
      " -2.2837e+00 -2.9072e+00  2.2329e+00  2.6300e+00  1.9300e+00 -1.6988e-01\n",
      "  4.0135e-01 -3.3784e+00 -2.3130e+00  3.8574e+00  2.4082e+00  2.2144e+00\n",
      "  3.8942e+00 -1.0634e+00  4.3413e+00 -8.5957e-01 -2.3111e+00  9.4194e-01\n",
      "  4.3923e-01 -2.9740e+00  2.9321e+00  4.1080e+00 -6.8308e-01  2.9347e+00\n",
      " -1.8762e-01  2.5873e+00  1.8262e+00  9.5776e-01  3.3403e+00 -6.1282e-01\n",
      "  1.4015e+00  1.5501e+00 -2.4793e+00 -2.7325e-01 -3.2722e+00  1.2653e+00\n",
      "  7.5106e-01  7.2658e-01  1.7287e+00 -2.6303e+00  2.4394e+00  2.8023e+00\n",
      " -2.7790e+00 -3.5765e-01 -1.7898e+00  2.1864e+00  6.5183e-01 -3.0847e+00\n",
      "  2.5490e+00 -1.6785e+00  1.2513e-01 -4.9002e+00  8.4505e-02 -2.5789e+00\n",
      "  1.8360e+00  7.9839e-01 -3.0835e+00 -2.7408e+00 -2.8503e-01 -1.9675e+00\n",
      "  1.0807e+00  1.0564e+00 -2.0592e+00  1.6305e-01 -1.2628e+00 -1.9288e+00\n",
      "  1.8783e+00  3.4752e+00 -4.1479e+00 -2.8586e-01 -1.1766e+00 -5.5371e-01\n",
      "  5.3477e-01  1.0254e+00 -2.1640e+00 -1.8605e+00 -2.0019e-01 -1.2568e+00\n",
      " -3.5321e+00  1.6856e+00  3.9734e+00  2.3861e+00 -1.5999e+00 -2.7622e+00\n",
      " -3.8621e+00 -1.1244e+00 -2.5624e+00 -1.1923e-01 -1.4338e+00  1.4961e+00\n",
      "  3.5770e-01  3.4087e+00 -8.3429e-01 -1.9981e+00 -5.6570e-01  1.1393e+00\n",
      "  1.7036e+00  4.6392e+00 -1.3920e+00 -9.8243e-01 -3.6559e-01  2.0761e-01\n",
      " -9.1107e+00 -3.6909e+00 -1.5041e+00 -5.6702e+00 -3.7057e+00  1.1791e+00\n",
      " -4.1611e-01  5.5637e+00 -3.5928e+00 -5.9342e+00 -2.8192e-01  4.9558e+00]\n",
      "es [-5.6793e+00 -1.8512e+00 -6.4663e+00 -1.5701e+00 -1.7709e+00 -4.9102e+00\n",
      "  3.6229e-01  5.4825e+00 -1.9252e+00 -3.7244e+00 -5.8188e+00  1.1560e-01\n",
      "  1.4540e+00 -3.2817e-01  6.1272e+00  8.3686e-01  3.8111e+00  9.7878e+00\n",
      "  2.2549e+00 -8.1546e-02  2.2825e+00  5.5878e+00  1.7403e+00  8.8573e-01\n",
      "  6.7450e-01 -6.0789e+00  8.9824e+00 -6.1621e+00 -5.8852e+00 -2.6952e+00\n",
      "  5.6971e+00  3.6461e+00  7.5074e+00  1.0035e+01 -3.2728e+00  5.3125e+00\n",
      "  6.7520e+00  4.2044e+00 -3.3453e+00 -7.9298e+00 -3.2169e-01 -5.0985e+00\n",
      "  6.2881e-01 -3.1642e-02 -5.4960e+00  1.8628e+00 -1.4535e+00 -4.0084e+00\n",
      "  4.4930e-01  2.7844e+00  3.0012e+00 -7.6546e+00 -4.8864e+00 -1.4684e+00\n",
      "  3.5212e-01  7.9418e+00  4.1146e+00 -4.9308e+00 -9.5812e+00 -5.6463e+00\n",
      "  3.2575e-03 -6.5321e+00  1.7621e+00 -3.1203e+00  2.7375e+00 -7.1510e-02\n",
      " -9.6761e+00  4.8141e+00  3.8258e+00  7.6489e-01 -5.2489e+00  2.5502e+00\n",
      " -2.0030e+00  2.6773e-01 -3.6694e+00 -5.3220e+00  4.3015e+00 -3.0232e+00\n",
      "  3.4700e+00 -6.8100e+00  6.4317e-01 -2.9558e+00 -2.6114e+00 -2.7943e+00\n",
      "  5.0055e-01  9.6057e+00  6.5513e-01 -2.2499e+00 -7.0968e+00 -4.7445e-02\n",
      " -1.1217e+01  1.1136e+01 -1.0104e+01 -1.5894e+00 -2.0177e+00 -1.4182e+00\n",
      " -1.7861e+00  1.7632e+00  3.2973e+00 -7.6738e+00  1.8839e+00  7.6234e+00\n",
      " -2.8009e+00 -7.4679e+00  1.4452e+01  3.6800e+00 -7.1060e+00 -7.5621e+00\n",
      " -3.3917e+00 -3.1225e+00  1.9260e+00  9.5816e-01  8.2727e+00 -8.6637e+00\n",
      "  1.2506e+01 -1.2909e+00 -2.9373e+00  8.3249e+00 -8.1119e+00  6.2721e+00\n",
      "  2.6410e+00 -4.2614e+00  8.6633e-01 -5.7488e+00  4.1103e+00 -1.3739e+00\n",
      "  4.4810e+00  4.6471e+00 -1.2007e+00 -3.6002e+00  1.7057e-01 -8.8081e-01\n",
      " -1.6238e+00 -2.1464e+00  1.5088e+00 -5.2244e-01  3.4701e+00  5.8893e+00\n",
      " -4.3679e+00  2.3091e+00  7.7860e-01 -1.9310e+00 -4.5129e+00 -5.2254e+00\n",
      " -4.4086e+00  4.4104e+00 -3.9207e+00 -6.2026e+00 -6.7935e-01 -3.7204e+00\n",
      " -6.1538e+00 -5.0541e+00  4.0058e+00  3.3396e+00  1.4919e+01  2.2070e+00\n",
      "  1.3073e+01  2.4054e+00  3.7916e+00 -2.0900e+00  8.8476e+00 -2.7136e+00\n",
      " -7.1181e-01  1.7846e+00  3.0911e+00  7.8419e-01  7.5858e+00  1.4634e+00\n",
      "  6.1390e+00 -3.3183e+00 -4.8051e+00  3.7584e+00  3.7589e+00 -9.1877e+00\n",
      "  2.2180e+00  2.7162e+00  2.5420e-02  1.4976e+01 -1.3336e+00  9.1680e-01\n",
      "  6.7548e-01  3.7865e+00 -9.0820e-01 -4.4770e+00 -3.5039e-01 -1.3328e+00\n",
      " -1.7333e+00  1.5628e+00 -1.0167e+00  4.8057e+00  9.3824e+00 -4.6797e+00\n",
      " -5.2970e+00  3.1235e+00 -3.6993e+00 -6.6008e+00  4.9394e+00  1.7168e+00\n",
      "  1.7518e+00  3.8966e+00  9.4657e+00  2.4849e+00  2.8873e+00 -2.7085e+00\n",
      " -4.2794e+00 -6.4094e-01 -4.9639e+00  3.9831e+00  6.0519e+00 -2.8366e+00\n",
      "  7.0977e+00  1.8850e+00  6.3536e+00 -8.3134e-01 -4.8723e+00 -4.3697e+00\n",
      "  1.1546e+01 -6.2943e-01 -7.9399e+00  9.2721e+00  5.3563e+00 -3.3393e+00\n",
      "  2.9409e+00  2.3881e+00  5.9634e+00 -8.0374e+00  2.2076e+00  1.1533e+00\n",
      " -3.1537e+00  4.6134e+00  4.8780e+00 -1.0705e+01  2.4478e+00  4.2472e+00\n",
      " -3.0886e+00  3.7781e-01  3.6692e+00 -6.9921e+00  4.5609e+00 -8.4389e-01\n",
      " -1.2373e+00  1.5734e+00 -3.7411e+00 -9.6875e+00 -2.4991e+00 -1.0408e-01\n",
      " -3.2911e+00 -2.3058e+00 -4.1707e-01  4.5125e+00  8.1631e-01 -1.0459e+00\n",
      "  9.2716e-02  5.4656e+00  7.4934e+00  1.1817e+00  1.3727e+00  2.8650e+00\n",
      "  1.0806e+01  4.5992e+00  4.8481e-01  3.8526e+00  7.3967e-01 -8.2820e+00\n",
      "  3.6596e+00 -3.4037e+00 -2.0364e+00 -6.1533e+00 -1.4264e+00 -3.7945e+00\n",
      "  1.0080e+01  7.3111e+00 -3.8673e+00  9.8427e+00 -3.0554e+00  7.5561e-01\n",
      "  7.2343e+00  2.7113e+00 -1.2247e+00  1.9379e-01  6.4191e+00 -7.7637e+00\n",
      "  3.6891e+00  7.2260e+00  6.7511e+00 -6.5187e-01  8.0058e-01  4.4493e+00\n",
      "  1.7007e+00 -6.5428e-01 -7.9830e+00 -1.7874e+00 -7.1266e+00 -1.6537e+00\n",
      "  2.0219e+00  3.5609e+00 -1.2801e+00 -4.8058e-01  6.5105e-01 -2.9644e+00]\n",
      "una [ 6.9647   -1.9416    1.7142   -0.84589   5.7276   -1.7475   -2.2724\n",
      " -2.5413    3.5464   -0.24333  -1.3675    7.4523    4.5846   -1.0843\n",
      "  1.2663   -0.90107  -0.19571  -4.1284    7.9354    2.2869    1.9479\n",
      "  1.0723   -1.1589   -0.16684   0.66249   1.6609    0.063071 -0.26603\n",
      " -1.9342   -3.4867   -0.40951   2.17      3.3741   -1.733    -4.014\n",
      "  2.9735    1.849    -0.4462    2.1588    2.1399   -1.0611   -0.1687\n",
      " -2.3849   -2.6605   -3.0812    2.7202    0.5324    5.3963   -1.4136\n",
      " -0.69632  -0.18297   2.2721    0.89729   2.5035   -2.437     1.2181\n",
      "  2.1052   -3.4936   -4.4677    2.8927    5.596     0.96077   3.4782\n",
      " -1.2367    1.3905    2.4175   -2.4804   -3.6864   -4.082     1.9689\n",
      " -0.11289  -0.10552   1.0047    1.3698   -3.5493   -1.6525    0.42256\n",
      " -3.7372    0.75918  -1.8879    1.5157   -4.2102   -2.2971    2.3245\n",
      " -0.13544  -0.14311  -2.1443   -1.5042   -0.92005  -0.7018   -7.5668\n",
      " -0.057341 -3.3137    0.16677   1.2076    4.3538    0.7852    1.8124\n",
      " -1.1067   -1.9301    0.50442  -2.2886    0.094662 -2.5073    0.2869\n",
      " -2.0935    0.10938  -2.5366    9.866     1.6842    0.97063  -3.9983\n",
      "  0.21689   3.6208    6.7019   -0.92471  -3.847    10.731    -1.6953\n",
      "  8.0325    0.94424   0.037933 -5.0915   -4.3535   -1.7139    3.4352\n",
      "  1.1531   -3.8916    0.97495  -2.816     0.20761   0.83448   5.2822\n",
      " -4.5395    4.1202   -0.85533  -2.9415    6.5651    3.8074    3.7666\n",
      " -0.34755   3.9245    3.5071   -2.6703   -1.9202    2.7909    3.2744\n",
      "  1.5989   -2.1731    5.747     2.9178    2.4876   -0.53734  -1.18\n",
      "  3.4647    2.461    -3.6592   -4.0534   -6.1197    2.1926    3.8257\n",
      " -2.2204   -0.98609   0.83257   6.5259    3.8644   -2.2138    0.70187\n",
      " -1.9485   -2.6196    4.7446    0.83369  -1.0769    3.0282    3.2527\n",
      "  0.36092  -4.872     0.54334  -1.2111   -3.9292    5.0806   -0.43462\n",
      "  0.1644   -0.52182  -2.099    -4.2319   -3.7893   -0.24337  -1.6134\n",
      " -4.1057    0.84814   3.2207    0.79625   0.91906  -3.5197    0.33221\n",
      "  4.3867    0.74852   4.1028   -1.8975    4.2037   -0.99167  -1.071\n",
      " -1.0801    1.4963   -0.23109   1.9278    2.0972   -2.5689    1.6316\n",
      " -0.28172   3.2984    1.6298   -1.2032    4.8632    0.77996   6.6853\n",
      "  0.39213  -1.8493    0.82373  -6.9701   -0.30084   1.0248    1.2882\n",
      "  3.3247   -3.27      5.008     1.9488    2.0579    0.48893  -0.48505\n",
      " -0.32161   2.0438   -1.13     -0.25906   0.24579  -0.65059  -7.1417\n",
      "  2.0174   -3.9889    0.43685  -0.88688  -1.0213   -1.6046    1.5132\n",
      "  1.5035   -0.037568 -0.81129  -1.9825    2.541    -1.8393   -2.3719\n",
      "  0.67914   4.8151    2.2606    4.4708   -2.23     -1.3143    0.37602\n",
      "  0.49207  -1.3781   -1.9916    1.4885   -0.40755   1.9162    1.7231\n",
      "  4.1304    4.1749   -2.869    -3.2376   -0.79297   2.846    -5.4802\n",
      " -0.6458   -1.344     3.8448   -1.89      6.1748   -1.0843   -2.3057\n",
      "  0.22129  -1.9115    0.76097   8.8013   -4.0556   -0.35458  -0.35506\n",
      " -1.6178   -3.8806   -0.77149   2.5049   -2.2745   -1.8049    1.1491\n",
      "  0.26773   2.7068   -4.9922   -0.53702  -0.038155  3.2226  ]\n",
      "oraciÃ³n [ 1.0669    3.1879    0.089692  0.30316   2.7144   -1.9492   -1.4913\n",
      "  3.2255   -1.3971    3.363     6.0155    0.14825   0.24945   2.7003\n",
      " -1.3058   -3.3707    0.96714   0.30017  -1.3244    3.2406   -1.004\n",
      "  0.13746  -1.5692    1.6315   -2.577     1.0259    1.5793    0.25758\n",
      " -2.2664   -1.109     3.6504    1.0193    0.67977  -2.8103    0.23402\n",
      "  0.79228  -2.7919   -0.17256   1.1955    1.6307   -1.6689    2.165\n",
      " -1.2349   -2.7273   -2.7546   -1.1544   -1.7046   -1.3949   -0.047519\n",
      "  0.46443   3.6545   -0.21319  -0.32522  -0.7538   -0.53397  -0.89866\n",
      "  0.13315  -1.8828   -1.3254    0.92723  -1.9649   -0.68355   0.90299\n",
      " -1.2894   -3.1813    1.8032   -2.4676    0.10106  -0.1536    1.6789\n",
      " -1.6176    0.042234  2.4839    0.42976  -1.7898    0.097776  3.2877\n",
      " -1.1419   -0.55434   2.4824   -3.232     1.4292   -1.3434   -1.3141\n",
      "  2.8214    0.31385   0.66741  -3.9545   -0.23422   3.2382   -1.6251\n",
      " -0.09715  -2.0103    3.6665    2.7237    1.3635   -1.8864   -1.3738\n",
      " -2.7941   -1.69      3.3105   -2.0887   -2.7281    1.8072   -2.9006\n",
      "  2.4127    0.2688   -1.4221   -3.3937    3.1186   -1.9413    0.9718\n",
      "  0.17689  -0.23599   4.135     1.4301    1.2028    3.5787   -4.0424\n",
      "  0.4072   -2.0712    3.2706   -2.1262    2.4189    0.85289   3.9496\n",
      "  0.33585  -0.38138   4.2529   -0.9915   -1.8044   -2.1496   -0.74252\n",
      "  0.41468   1.3296   -1.8761    1.8408    0.22956   1.8818   -0.31911\n",
      " -1.0952    1.17      2.2008   -0.55399   0.4662   -2.926     1.5987\n",
      "  0.85576  -3.358     0.24886   0.54633  -0.17165   0.92053   1.4421\n",
      "  0.7028   -0.12248  -4.4359   -0.86234   0.37413   4.9381   -0.37241\n",
      "  0.06004  -3.2602   -0.89095   4.1043   -1.4628   -3.9156   -1.7251\n",
      "  2.9711   -5.1097   -0.90675   1.032     0.86631   3.0993    0.53583\n",
      " -0.88586  -0.99661  -0.34143   2.177    -0.93561  -0.075105  2.5738\n",
      "  1.9489    2.0219   -0.14635  -1.6274   -1.2565   -0.37843  -2.7594\n",
      "  0.28217   3.0697    3.4685   -0.21204   1.1009   -0.61862   0.13278\n",
      "  2.5263    4.9227    1.1228   -1.2742   -0.12263  -1.184     0.54539\n",
      " -2.5622    2.1821    0.7103    2.2094    0.25086   0.45283   2.8977\n",
      " -1.2086    0.14601   0.62503   0.9197   -2.7258    3.7808    0.40119\n",
      " -0.87798   1.4024    0.09878  -1.2646    0.9856   -0.66366  -0.31928\n",
      "  0.84449  -1.4004    0.86699  -0.33216  -1.3882   -1.3974   -1.6511\n",
      " -1.2636   -0.81434  -1.7016   -0.76452  -2.9636    2.8478   -0.076719\n",
      "  1.8212   -2.241     0.10976  -1.1604   -3.6341    4.1896   -0.099208\n",
      " -1.5972   -0.69193   1.2454    0.050732  1.7665    0.90471   3.244\n",
      "  0.44948   3.297    -0.019593  1.8721   -2.6863   -2.2348    0.38639\n",
      "  1.9064   -2.124    -2.9868    1.5219   -0.92927   0.5873   -2.7282\n",
      "  1.7511    2.3359    0.87144   1.6088    2.135    -1.8231    0.58514\n",
      " -1.1385   -1.2059   -1.446    -1.111     0.37793   1.4005    0.50588\n",
      " -2.4005    1.5355   -2.8159    2.7368   -3.3387    1.3263    0.79685\n",
      "  0.1562    1.6569    0.66421   1.6719    2.5094   -2.8384    3.4379\n",
      "  0.75189   0.82565  -0.95448   0.010863 -0.92427  -2.2247  ]\n",
      "de [ 3.8853e-01  9.9683e-02  5.9997e+00 -8.3435e-01  3.7426e+00 -1.3226e+00\n",
      "  3.3948e+00 -2.8459e+00  3.2895e+00 -2.7674e+00 -1.8199e+00  5.8592e+00\n",
      "  1.8985e+00  1.2966e+00 -4.7495e+00  2.9580e+00  5.3088e+00  1.1556e+00\n",
      "  1.0316e+00  3.1661e+00  5.0065e-01  6.6373e-01  1.2299e+00  1.0512e+00\n",
      " -1.7420e-03  4.6153e+00 -1.9621e+00  6.4910e+00 -1.3927e+00 -6.9031e+00\n",
      "  1.1644e+00  3.5639e+00  2.3457e+00  1.4812e+00  2.0457e+00 -5.5955e+00\n",
      "  3.4128e-01 -6.3943e-01  6.2033e-01 -4.3092e+00 -1.7449e+00 -1.2369e+00\n",
      " -6.7810e+00  1.6553e+00 -5.3376e+00  4.6547e+00 -3.6411e+00  1.0734e+00\n",
      " -5.2617e+00  5.5084e+00  9.0538e-01  4.6132e-01  7.9270e-01  2.5153e+00\n",
      " -2.8288e+00 -3.4798e+00 -4.0388e+00  1.5300e+00 -2.5683e+00 -4.9229e+00\n",
      "  1.4632e+00  3.1376e+00 -3.1685e+00  2.5889e-01 -7.5349e-02  1.1427e+00\n",
      " -1.7928e+00 -3.5775e-01 -3.2911e+00 -4.3720e-01  5.4351e+00  2.3845e+00\n",
      " -1.2131e+00  9.7459e-01 -9.1397e-01  4.6999e+00 -2.5023e+00  6.7552e+00\n",
      "  3.4132e+00  3.0741e-01 -1.2081e+00 -1.7034e+00 -7.2081e+00  6.1108e+00\n",
      "  7.1032e+00  1.3942e+00  3.4747e+00  1.1927e+00  8.4810e+00 -1.0790e+00\n",
      " -4.3359e+00  7.4692e+00 -3.7461e+00  2.9745e+00  8.0054e+00  1.2217e+00\n",
      "  3.5651e+00  7.7388e-02 -5.2886e+00  2.0232e+00  4.1426e+00  6.6273e+00\n",
      "  9.4797e-01 -2.7646e+00  2.2497e-02  9.2676e-01  8.8256e+00 -1.0035e+00\n",
      "  7.3562e+00  2.5846e+00 -1.0192e+00 -1.9798e+00  5.3717e+00  1.6100e+00\n",
      "  2.8159e-01 -5.2795e-01 -2.6026e+00  7.6894e+00  2.2893e+00  1.7462e+00\n",
      "  2.3056e+00  7.0429e-02 -1.5412e+00  4.3700e+00  5.5779e-01 -5.7326e+00\n",
      "  1.7521e+00 -3.6239e+00  3.5229e+00  2.9693e+00  2.0880e+00 -5.2604e+00\n",
      "  3.2570e-01 -4.5678e+00  2.8131e+00 -2.2431e+00  4.1753e+00  5.1687e-01\n",
      "  1.8863e+00  3.3885e-01  3.4083e+00  4.1707e+00  4.1664e+00  1.5076e+00\n",
      " -5.5106e+00 -8.6316e-01  6.5511e+00 -3.0308e+00  9.1743e-01 -3.7669e+00\n",
      "  1.4818e-01 -1.9747e+00 -2.7144e+00  1.0517e+01  6.4987e-01 -6.0261e+00\n",
      " -1.5951e+00  2.0249e+00 -2.1660e+00  3.1278e+00 -1.2226e+00 -3.2490e+00\n",
      " -1.6541e+00  3.2519e+00  3.8946e+00  1.0736e+00 -8.0597e+00 -3.2828e+00\n",
      " -3.3472e+00  2.1651e-01  3.8899e+00  7.7653e+00 -8.0672e-01  4.5563e+00\n",
      "  5.4883e+00  3.1865e+00 -3.0638e-01 -3.4764e+00  1.0345e+00  1.6414e+00\n",
      "  1.6732e+00 -5.1419e+00  8.7651e+00 -3.8972e+00 -4.1165e+00 -1.1898e-01\n",
      "  1.2480e+00  2.5309e+00 -2.3664e+00  3.8911e-01  2.0060e+00  4.5085e+00\n",
      " -1.9312e+00  3.8323e+00 -4.9607e-01  1.2940e+00  1.1626e+00  5.0553e-01\n",
      " -2.3623e+00  2.1824e-02  5.3138e+00 -4.7562e+00  7.4819e-01 -3.3198e+00\n",
      " -3.2388e+00 -3.1226e-01 -2.9787e+00 -1.7117e-01 -3.6033e+00 -3.8958e+00\n",
      " -3.3316e-01  3.8892e+00  5.4959e+00  2.9423e+00 -6.6152e+00  4.3479e+00\n",
      "  3.3393e+00 -2.9967e-01 -5.9462e+00 -1.5880e+00 -5.8022e+00 -1.1291e-01\n",
      "  8.3164e-01  1.5680e-01  3.5696e+00 -2.4067e-01 -1.9625e+00  4.0149e+00\n",
      " -1.0061e+00  3.5976e+00 -1.7236e+00  1.9073e-01  3.4536e-01 -7.6572e+00\n",
      " -1.4809e+00 -2.5989e+00 -1.5574e+00  2.7007e+00  5.5058e-01 -3.3936e-01\n",
      "  2.7240e+00 -5.1807e+00 -5.5120e+00 -6.6310e-02  2.3108e-01  5.9779e-01\n",
      "  1.2288e-01  2.5872e+00 -2.9693e+00  9.4024e-01  1.8434e+00 -2.7392e+00\n",
      " -4.2921e-01  6.7019e+00  1.0637e+00  3.4067e-01  7.2850e-01 -3.7815e+00\n",
      " -7.2656e-02  5.4724e+00 -1.5931e+00  3.1264e+00 -6.3163e+00 -3.4369e+00\n",
      " -1.5788e-01 -4.4337e+00  1.8168e+00  4.7803e+00 -1.6829e+00  4.6716e+00\n",
      "  2.2803e+00 -4.1303e+00 -3.6062e-01 -7.9154e+00  3.7617e+00  9.8983e-01\n",
      "  2.6061e+00  5.3093e+00  1.9958e-01 -1.2893e+00 -2.5801e+00 -1.1266e+00\n",
      "  5.2716e+00  1.6271e+00  7.1610e-01  2.9600e+00  2.7553e+00 -8.0815e-02\n",
      " -2.7592e-01 -3.1699e-01 -7.3229e+00 -1.1847e+00  1.0714e-02 -3.5671e+00\n",
      "  7.0618e-01 -1.4291e+00 -1.5576e+00  2.1233e+00  9.2697e-01  1.5009e+00]\n",
      "ejemplo [-1.0949e+00  9.9512e-01  5.8120e-01 -7.7734e-01  1.8600e-01 -2.8830e+00\n",
      " -2.0063e+00  9.9193e-01 -3.4627e-01  1.1219e+00  4.4047e-01  4.4649e-01\n",
      " -2.7873e-01  1.1128e+00 -2.2509e-01 -9.8033e-01  1.3800e-01  1.1206e+00\n",
      " -9.2279e-01  7.9510e-01 -4.9270e-01 -8.7835e-02  1.0781e+00  9.9224e-01\n",
      "  6.8455e-01  2.6165e-01 -5.7017e-01  2.9398e-01  8.5659e-01  4.3767e-01\n",
      "  7.1694e-01  7.5092e-01 -4.6836e-01  1.7940e+00  2.2381e-02 -2.0423e+00\n",
      "  1.6662e+00 -2.1658e+00  1.8303e+00 -5.5100e-01  5.9148e-01  2.7665e-01\n",
      "  4.8634e-01 -3.3982e-01 -9.7305e-01 -1.4469e-01 -9.9702e-01  7.3538e-01\n",
      " -1.8000e+00  6.1598e-01  8.2237e-01 -1.0450e+00  1.6233e-01  1.7935e+00\n",
      " -1.6690e+00  2.4187e-01  1.2904e+00  8.3976e-01 -1.7959e+00  1.5149e+00\n",
      " -7.0589e-01  1.9746e-01 -1.6310e-01 -4.9273e-01 -1.5331e-01  1.3582e+00\n",
      " -4.1662e-01 -8.6956e-01 -2.7093e+00  1.4762e+00  1.9818e-01  1.2300e+00\n",
      "  3.3755e+00  8.1172e-01 -2.2522e+00  5.6562e-01  1.1636e+00 -1.3397e+00\n",
      " -3.9382e-01 -8.4137e-01 -2.5008e+00  1.2292e+00 -1.2338e+00  4.8148e-01\n",
      "  8.5390e-01  1.9593e+00 -8.7536e-01  2.6211e-01  7.3906e-01 -1.0512e+00\n",
      " -8.5508e-01 -1.6240e+00 -1.0929e+00  2.9693e+00 -1.0338e-01  1.4548e+00\n",
      "  1.1475e+00  1.1024e+00 -2.0060e-01  1.2258e+00 -7.0088e-01  7.8098e-01\n",
      "  4.4974e-01  7.6454e-01 -5.3264e-01  2.9295e+00  6.6817e-01 -1.0476e+00\n",
      " -7.0164e-01  6.6390e-01  3.3901e-01  1.7400e-01 -3.1202e+00  3.7183e-01\n",
      "  1.8593e+00 -5.6895e-02  4.5654e-02  2.4312e+00 -2.1505e+00  3.8056e-01\n",
      " -4.2394e-01  3.0277e-02  7.3828e-02 -3.3068e-01 -5.1723e-01  1.1614e+00\n",
      "  1.6790e+00  1.3989e+00  2.3327e+00 -1.7826e-01 -5.7417e-01  8.1227e-01\n",
      "  6.3473e-01  6.7599e-03  3.9268e-01 -6.8762e-02  1.3287e+00  5.6098e-01\n",
      "  3.2954e-01 -1.2846e-01  3.8109e-01  9.0014e-01 -9.0808e-01 -4.4226e-01\n",
      " -6.1801e-01  1.8642e+00  1.0922e+00 -1.1046e+00 -5.9820e-01  8.0851e-02\n",
      " -2.0678e+00 -2.6485e+00 -9.4384e-01  2.2040e+00  1.4764e+00 -2.4647e-01\n",
      "  7.7753e-01 -3.0590e-01  7.9947e-01  8.1729e-02  5.1436e-01 -3.4921e-01\n",
      " -1.2026e-01 -1.7514e+00  1.5119e+00  2.1258e-01 -3.8533e-01 -1.1022e+00\n",
      "  1.5851e-01 -1.0587e-01  1.5532e+00  1.1184e+00  5.4577e-02 -3.9067e-01\n",
      "  2.1931e-01 -6.2890e-01  3.1772e-01  2.5782e+00  1.0637e+00 -1.1226e+00\n",
      " -1.4713e+00  2.2956e+00 -6.0334e-02 -2.3202e-01  1.2078e+00 -1.5849e-03\n",
      " -1.3255e+00  1.1979e+00 -3.2242e+00 -1.1408e+00  3.0518e+00 -1.1989e+00\n",
      "  1.1363e+00  2.1081e+00 -2.5109e+00 -1.1886e+00  1.0547e+00  2.3447e+00\n",
      " -1.1586e+00  4.9376e-02  1.3017e+00 -1.6499e+00  1.4927e+00 -2.2573e+00\n",
      "  1.1685e+00  1.8582e-01  1.2977e+00  5.0826e-01  2.8468e-01  2.3338e+00\n",
      " -6.8703e-01  1.5998e+00 -3.9740e-01  3.4098e-01 -1.6627e+00  1.7972e+00\n",
      "  1.7055e+00 -5.0664e-01 -9.1895e-01 -8.8223e-02 -1.2184e+00 -4.8939e-01\n",
      "  5.5009e-01  1.0013e+00  1.4590e+00 -1.2020e+00  5.7665e-01  2.2031e+00\n",
      "  1.2581e+00  8.7032e-01  5.2647e-01 -1.9041e+00 -1.0510e+00  2.8049e+00\n",
      " -4.2764e-01  2.2382e+00  6.9823e-01  5.8862e-01  9.2730e-01  5.5621e-01\n",
      " -1.4243e+00  4.1001e-01 -9.1536e-01  1.6688e+00  5.3927e-01 -1.9279e+00\n",
      " -1.0384e+00  3.1854e-03 -4.1908e-01  8.0669e-01 -4.0375e-02  9.3335e-01\n",
      " -9.7592e-01 -1.0581e+00  1.9630e+00 -4.6325e-01  6.8774e-01 -4.1013e-01\n",
      " -6.2882e-01 -7.2495e-01  1.0102e+00 -2.0532e-02 -5.9592e-01 -5.3856e-01\n",
      "  3.2396e+00 -2.2658e+00  2.8066e-01  1.9865e+00  9.0392e-01  7.4247e-01\n",
      "  1.0348e+00  8.2440e-01  7.3042e-01  6.9948e-01  1.2270e+00  5.5513e-01\n",
      " -1.1284e+00 -2.9988e-02  1.1635e+00 -5.0546e-02 -6.7268e-01 -1.5704e+00\n",
      " -2.3371e-02  1.6862e+00 -1.3060e+00  1.9122e+00  1.6221e+00  7.8207e-01\n",
      " -9.1283e-02  2.1072e+00  1.1816e+00  2.0755e-01  6.7666e-01 -3.9904e-01\n",
      " -5.2382e-01 -1.7637e+00 -8.3047e-01  1.0553e+00  7.3043e-01 -2.3459e-01]\n",
      ". [ 1.6517   -1.9634   -0.60317  -1.4497   -4.6456   -2.6548    1.7871\n",
      "  2.0086    2.5595   -6.62     -3.1862    1.4241    1.2941    2.3816\n",
      " -2.2026    3.1901   -0.069615  3.4981    0.52599   2.1718    0.68467\n",
      " -0.89486  -2.184     1.1761   -0.067467  0.72529   2.7139    0.59838\n",
      "  2.4567   -8.4852   -1.5334    1.765     0.074411  2.7647   -0.011132\n",
      " -3.8116   -2.1176    1.4034   -3.6477    1.435     1.5079   -3.9402\n",
      " -2.6653   -2.438    -2.5748    0.78063  -4.2288   -5.5485    1.2281\n",
      "  3.5425    2.5387   -1.5244   -2.9497    5.9991   -0.013804  0.53404\n",
      " -1.8439    0.8998   -3.0015   -1.8224   -2.5184    1.1081   -2.1192\n",
      " -1.2046    1.045    -0.61409   1.0887   -2.6562   -0.41009  -2.9739\n",
      "  3.899     2.4347    0.74896   1.858     1.002     1.6324   -0.90548\n",
      "  6.6497    0.24717  -0.42803  -0.10038  -2.6809   -1.1805   -3.3625\n",
      "  2.1539   -0.10481   3.3057    3.112     5.7779   -5.0753   -2.127\n",
      "  2.1877   -6.2819   -1.6592   -4.0378    2.2019   -1.9772   -1.5248\n",
      " -3.5156   -3.1314    0.23034   0.89325   0.33181   1.6749    0.81533\n",
      " -0.88029   1.2501   -1.1932    2.5691    0.74317  -0.88583   1.0391\n",
      "  7.776    -3.162    -2.6456    4.8706    0.61319  -0.68245   1.7849\n",
      "  3.6145    1.0658   -2.9448    1.2607    2.7204    2.6704   -0.25994\n",
      " -1.2124   -0.13574   0.97574   0.10461  -2.35     -7.8595    0.17082\n",
      " -2.864    -0.43391   2.6371    0.86701  -1.6068    2.0415   -1.7224\n",
      "  1.2635    3.1676   -2.7371    4.5863   -1.063     0.68731  -0.6117\n",
      " -0.89254   2.0062    1.002    -0.16514   0.62088  -0.93454   1.5502\n",
      "  1.0427   -3.2031    2.3137    2.2351   -1.1178   -0.016491 -2.593\n",
      " -2.4076    1.5886    3.8658   -3.5407    2.3651   -0.1282   -2.2884\n",
      " -4.1526    1.5237   -1.6451    3.958    -2.5176    1.271     5.5891\n",
      " -0.073714  1.7153    7.2809    0.67752  -0.11758   1.2539   -2.1887\n",
      " -1.5756    2.315    -2.6269   -0.78974   1.0015    0.38805  -0.87827\n",
      "  2.229     0.4337    3.5694    0.77441   2.4085   -0.81812   2.577\n",
      "  0.17484  -5.6634    0.70201   1.3582    1.3136    1.7878    2.3947\n",
      " -0.053988  0.30324   0.8196    0.54558   4.4698   -0.57433  -1.4294\n",
      "  3.3957   -1.1672    1.2204   -0.30839   2.2115    3.1325    5.957\n",
      "  5.6923   -6.7601   -0.2131   -0.73857  -0.73549  -2.4655    2.1199\n",
      "  3.8113    0.60626  -0.5744   -0.39691  -0.49172   3.1223    2.1085\n",
      " -0.35509   0.76224   1.7729   -3.1049   -4.8747   -4.7791    1.6022\n",
      " -0.42757  -2.6162    0.51915  -2.0794   -0.24428  -0.1492    2.1878\n",
      "  4.5774   -2.5017    2.8651   -1.6572    1.9492    1.4551    0.46257\n",
      " -1.8519    4.2251    2.1565    3.3613   -1.3283    2.9527    1.9768\n",
      "  2.5539    1.4193    6.8043    2.6752   -2.2353   -0.17639   1.1861\n",
      "  0.9132    1.835     0.20752   1.6543    0.99623  -1.8868    1.8383\n",
      " -1.7074    0.28406   4.3414   -0.044696  1.4921    0.49855   1.0152\n",
      "  2.1297    0.19676   2.6029    3.414     2.5571    5.8898    1.7887\n",
      "  3.6939    3.3534   -2.6737   -2.9593    0.7448    2.1898    0.79826\n",
      "  2.6447   -1.9847   -3.3541   -0.39062  -1.8326   -3.0347  ]\n"
     ]
    }
   ],
   "source": [
    "# Load the Spanish language model\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "# Example text\n",
    "text = \"Esta es una oraciÃ³n de ejemplo.\"\n",
    "\n",
    "# Process the text with spaCy to obtain word embeddings\n",
    "doc = nlp(text)\n",
    "\n",
    "# Access word embeddings for each token\n",
    "for token in doc:\n",
    "    print(token.text, token.vector)  # `token.vector` gives the word embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "[ 1.2771758  -0.24261244  0.5443317  -0.5648171   1.6554718  -2.8524573\n",
      " -0.09760858  1.0279129   1.2620614  -1.4583185 ]\n"
     ]
    }
   ],
   "source": [
    "# Function to get the average word vector of a sentence\n",
    "def get_sentence_embedding(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    # Collect embeddings of all tokens that have vectors\n",
    "    vectors = [token.vector for token in doc if token.has_vector]\n",
    "    \n",
    "    if len(vectors) > 0:\n",
    "        # Average the vectors if valid embeddings exist\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # If no valid tokens, return a zero vector of size 300 (or whatever your embedding size is)\n",
    "        return np.zeros(nlp.vocab.vectors_length)\n",
    "\n",
    "# Example of sentence embedding\n",
    "sentence_embedding = get_sentence_embedding(\"Esta es una oraciÃ³n de ejemplo.\")\n",
    "print(sentence_embedding.shape)\n",
    "print(sentence_embedding[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3326633165829146\n"
     ]
    }
   ],
   "source": [
    "# encoding our dataset\n",
    "X_train_embeddings = np.array([get_sentence_embedding(sentence) for sentence in X_train])\n",
    "X_test_embeddings = np.array([get_sentence_embedding(sentence) for sentence in X_test])\n",
    "\n",
    "# Initialize and train classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "accuracy = clf.score(X_test_embeddings, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.35678391959798994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize an MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
    "\n",
    "# Train the MLP\n",
    "mlp.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = mlp.score(X_test_embeddings, y_test)\n",
    "print(f\"MLP Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5262981574539364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53      1493\n",
      "           1       0.53      0.52      0.52      1492\n",
      "\n",
      "    accuracy                           0.53      2985\n",
      "   macro avg       0.53      0.53      0.53      2985\n",
      "weighted avg       0.53      0.53      0.53      2985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)  # You can experiment with the 'kernel' parameter\n",
    "svm_model.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test_embeddings)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"SVM Accuracy: {accuracy}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
